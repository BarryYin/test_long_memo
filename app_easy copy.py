import streamlit as st
import json
import os
import yaml
from openai import OpenAI
import datetime

def log(msg):
    timestamp = datetime.datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {msg}")

# --- Configuration & Setup ---
st.set_page_config(page_title="Collection Agent (Easy Mode)", layout="wide")

# Configure OpenAI
api_key = os.getenv("OPENAI_API_KEY")
if not api_key and "OPENAI_API_KEY" in st.secrets:
    api_key = st.secrets["OPENAI_API_KEY"]

if not api_key:
    st.error("OpenAI API Key is missing. Please set it in environment variables or .streamlit/secrets.toml")
    st.stop()
base_url = os.getenv("OPENAI_BASE_URL")

client = OpenAI(api_key=api_key, base_url=base_url)
MODEL_NAME = "gpt-4o-mini"

# --- Helper Functions ---
def load_config(config_path):
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def call_llm(prompt, system_prompt="You are a helpful assistant.", json_mode=False):
    try:
        kwargs = {
            "model": MODEL_NAME,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.7
        }
        if json_mode:
            kwargs["response_format"] = {"type": "json_object"}
            
        log(f"Calling LLM... Model: {MODEL_NAME}, JSON_Mode: {json_mode}")
        response = client.chat.completions.create(**kwargs)
        log("LLM Response received.")
        return response.choices[0].message.content.strip()
    except Exception as e:
        log(f"LLM Error: {e}")
        st.error(f"LLM Error: {e}")
        return "Error"

# --- Agent Layers (Adapted for Streamlit) ---

class Layer1StrategyManager:
    def __init__(self, config, history_logs):
        self.config = config
        self.history_logs = history_logs

    def generate_initial_strategy(self, customer_profile):
        system_prompt = "ä½ æ˜¯å‚¬æ”¶ç­–ç•¥ç»ç†ã€‚æ ¹æ®å®¢æˆ·ä¿¡æ¯ã€å†å²è®°å½•ä»¥åŠå…¬å¸çš„åŸºç¡€é…ç½®è§„åˆ™ï¼Œåˆ¶å®šä»Šå¤©çš„å‚¬æ”¶ç­–ç•¥ã€‚"
        user_prompt = f"""
        å®¢æˆ·èµ„æ–™ï¼š{json.dumps(customer_profile, ensure_ascii=False)}
        å®¢æˆ·èµ„æ–™å°†æœ‰åŠ©äºä½ åˆ†æå®¢æˆ·å½“å‰çš„ç»æµèƒ½åŠ›
        
        å†å²è®°å½•ï¼š{json.dumps(self.history_logs, ensure_ascii=False)}
        åŸºäºæ­¤è®°å¿†ä½“ï¼Œæˆ‘ä»¬èƒ½æ€»ç»“å‡ºæˆ‘ä»¬æ¯å¤©ä¸å®¢æˆ·äº¤æµçš„å†…ï¼Œå®¢æˆ·çš„è¿˜æ¬¾æ„æ„¿ä¸è¿˜æ¬¾èƒ½åŠ›å—ï¼Ÿå®¢æˆ·æ‹’ç»è¿˜æ¬¾çš„ç†ç”±æ˜¯å¦åˆç†
        æ³¨æ„ï¼Œå†å²è®°å½•æ˜¯éå¸¸é‡è¦çš„èµ„æ–™æ¥æºï¼Œè¯´æ˜æˆ‘ä»¬å·²ç»ä¸å®¢æˆ·äº¤æµè¿‡äº†ï¼Œä½†å®¢æˆ·å¯èƒ½å› ä¸ºå„ç§åŸå› è¿˜æ²¡æœ‰è¿˜é’±ï¼Œç°åœ¨å¸Œæœ›æ˜¯å»¶ç»­ä¹‹å‰çš„å¯¹è¯ï¼Œç»§ç»­ç»™å®¢æˆ·æ–½åŠ å‹åŠ›ã€‚

        *** å…³é”®çº¦æŸ ***
        ç›®æ ‡ï¼šå°½å¿«æ‹¿å›é’±ã€‚

        è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
        
        ã€å†å²åˆ†æã€‘
        ï¼ˆåœ¨æ­¤å¤„ç®€è¦åˆ†æå®¢æˆ·æ˜¨å¤©çš„æ€åº¦ã€æ‰¿è¯ºã€è¿˜æ¬¾èƒ½åŠ›å’Œæ„æ„¿ï¼‰
        
        ã€ä»Šæ—¥ä¸´æ—¶å‚¬æ”¶ç­–ç•¥ã€‘
        1. æ²Ÿé€šåŸºè°ƒï¼š...
        2. é‡ç‚¹å¼ºè°ƒçš„å†…å®¹ï¼š...
        """
        return call_llm(user_prompt, system_prompt)

    def update_strategy(self, current_strategy, feedback, chat_history, customer_profile, layer3_advice):
        system_prompt = "ä½ æ˜¯å‚¬æ”¶ç­–ç•¥ç»ç†ã€‚Layer 3 è¯„ä¼°è®¤ä¸ºå½“å‰ç­–ç•¥å›æ¬¾å¯èƒ½æ€§è¾ƒä½ï¼Œè¯·æ ¹æ®å»ºè®®è°ƒæ•´ç­–ç•¥ã€‚"
        user_prompt = f"""
        
        å®¢æˆ·èµ„æ–™ï¼š{json.dumps(customer_profile, ensure_ascii=False)}
        å†å²è®°å½•ï¼š{json.dumps(self.history_logs, ensure_ascii=False)}
        å½“å‰ä¼šè¯å†å²ï¼š{json.dumps(chat_history, ensure_ascii=False, indent=2)}


        Layer 3 è¯„ä¼°ä¸å»ºè®®ï¼š
        {layer3_advice}

        è¯·æ ¹æ® Layer 3 çš„å»ºè®®æ–¹å‘ï¼Œç»“åˆå®¢æˆ·èµ„æ–™ã€å†å²è®°å½•ã€å½“å‰ä¼šè¯å†å²ï¼Œé‡æ–°åˆ¶å®šä»Šå¤©çš„å‚¬æ”¶ç­–ç•¥ã€‚

        æŠ“ä½å®¢æˆ·çš„å€Ÿæ¬¾éœ€æ±‚ï¼ŒæŒ‡å®šæœ‰è¯´æœåŠ›çš„ç­–ç•¥ï¼Œæ¯”å¦‚å®¢æˆ·æ˜¯é•¿æœŸé«˜é¢‘å€Ÿè´·è€…ï¼Œå®ƒä¼šæ‹…å¿ƒä¿¡ç”¨ç¼ºå¤±ã€‚

        å¦‚æœå®¢æˆ·æ˜¯åˆæ¬¡å€Ÿè´·ï¼Œæˆ–è€…ä½é¢‘å€Ÿè´·è€…ï¼Œè¿™ä¸ªæ—¶å€™å¯ä»¥é€‚å½“çš„ç»™äº›å‹åŠ›ï¼Œæ¯”å¦‚ä½ å¦‚æœä¸€ç›´ä¸é…åˆæˆ‘ä»¬ï¼Œæˆ‘ä»¬ä¼šä¸ç´§æ€¥è”ç³»äººæ²Ÿé€š
        
        è¯·ç›´æ¥è¾“å‡ºä¿®æ”¹åçš„æ–°ç­–ç•¥ã€‚
        """
        return call_llm(user_prompt, system_prompt)

class Layer2Executor:
    def __init__(self, config):
        self.config = config
        self.base_system_prompt = self.config.get('system_prompt', '')

    def execute(self, strategy, chat_history, user_input, history_logs=""):
        # Clean up the base prompt
        cleaned_base_prompt = self.base_system_prompt.replace("You must output a JSON object", "")
        cleaned_base_prompt = cleaned_base_prompt.replace("Output Format", "")
        
        combined_system_prompt = f"""
        {cleaned_base_prompt}
        
        # KEY CONTEXT (Read Carefully)
        1. **HISTORY (Last Interaction)**:
        {history_logs}
        
        2. **TODAY'S STRATEGY (Your Supreme Command)**:
        {strategy}
        
        3. **CONFIG RULES (Reference)**:
        {json.dumps(self.config, ensure_ascii=False, indent=2)}

        # INSTRUCTIONS
        You are a smart, adaptive Collection Expert.
        
        **YOUR GOAL**: Execute the "TODAY'S STRATEGY" effectively. 
        - If the Strategy says "be nice", be nice. 
        - If it says "threaten blacklist", threaten it.
        - **Strategy > All Config Rules**.
        
        **REQUIRED THINKING PROCESS (JSON)**:
        1. "user_analysis": Briefly analyze the user's current resistance.
        2. "strategy_check": COPY & PASTE the specific sentence from "TODAY'S STRATEGY" that applies to this exact moment. (Do not skip this).
        3. "tactical_plan": How will you apply that specific strategy sentence to your reply?
        4. "response": The final Chinese message. Be natural, professional, and vary your sentence structure. Do NOT sound like a script.
        """
        
        messages = [{"role": "system", "content": combined_system_prompt}]
        for msg in chat_history:
            messages.append({"role": msg['role'], "content": msg['content']})
        messages.append({"role": "user", "content": user_input})
        
        try:
            log("Layer 2: Sending request to OpenAI...")
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages,
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            log("Layer 2: Response received.")
            content = response.choices[0].message.content.strip()
            data = json.loads(content)
            
            # Combine thoughts for UI display
            full_thought = (
                f"**User Analysis**: {data.get('user_analysis', 'N/A')}\n\n"
                f"**Strategy Check**: {data.get('strategy_check', 'N/A')}\n\n"
                f"**Tactical Plan**: {data.get('tactical_plan', 'N/A')}"
            )
            
            return data.get('response', ''), full_thought
        except Exception as e:
            log(f"Layer 2 Error: {e}")
            return f"System Error: {e}", ""

class Layer3Evaluator:
    def evaluate(self, chat_history, history_logs, customer_profile, current_strategy):
        system_prompt = """
        ä½ æ˜¯å‚¬æ”¶ç­–ç•¥çš„è¯„ä¼°ä¸“å®¶ã€‚
        ä½ çš„ä»»åŠ¡æ˜¯è¯„ä¼°å½“å‰ç­–ç•¥åœ¨å®¢æˆ·èº«ä¸Šçš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯"å®¢æˆ·å›æ¬¾çš„å¯èƒ½æ€§"ã€‚

        ä½ éœ€è¦ç»¼åˆåˆ†æï¼š
        1. è¿‡å»çš„å‚¬æ”¶å†å²è®°å½•ï¼ˆå†å²æ—¥å¿—ï¼‰
        2. å½“å‰çš„å®Œæ•´å¯¹è¯å†å²
        3. å®¢æˆ·çš„èµ„æ–™ä¿¡æ¯
        4. å½“å‰çš„å‚¬æ”¶ç­–ç•¥

        åŸºäºä»¥ä¸Šå…¨éƒ¨ä¿¡æ¯ï¼Œåˆ¤æ–­æŒ‰ç…§å½“å‰ç­–ç•¥ç»§ç»­ä¸‹å»ï¼Œå®¢æˆ·å›æ¬¾çš„å¯èƒ½æ€§æ˜¯ å¤§(HIGH)ã€ä¸­(MEDIUM) è¿˜æ˜¯ å°(LOW)ã€‚
        
        å¦‚æœå›æ¬¾å¯èƒ½æ€§ä¸º å°(LOW)ï¼Œä½ éœ€è¦ç»™å‡ºç­–ç•¥è°ƒæ•´å»ºè®®ã€‚ä½ å¯ä»¥ä»ä»¥ä¸‹6ä¸ªç»´åº¦ä¸­é€‰æ‹©æœ€é€‚åˆå½“å‰æƒ…å†µçš„åˆ‡å…¥ç‚¹ï¼ˆæŒ‡å¯¼ç¬¬ä¸€å±‚ç­–ç•¥ä¿®æ”¹ï¼‰ï¼š
        1. å®¢æˆ·è¿˜é’±ï¼Œä¼šè·å¾—å¥½çš„ä¿¡ç”¨ï¼Œæå‡ä¼šå‘˜ç­‰çº§ï¼›
        2. ä¼šæå‡è´·æ¬¾é¢åº¦å’Œç¬”æ•°ï¼›
        3. ä¼šè·å¾—è¿˜æ¬¾æŠ˜æ‰£ï¼›
        4. ä¼šå½±å“ä¿¡ç”¨åˆ†ï¼Œé™ä½è´·æ¬¾é¢åº¦ï¼›
        5. åç»­è´·æ¬¾ä¼šå¾ˆå›°éš¾ï¼Œæˆ‘ä»¬ä¼šåœæ‰ä¸å®¢æˆ·çš„åˆä½œï¼›
        6. æ‹‰å…¥é»‘åå•ï¼Œå®¢æˆ·çš„è´·æ¬¾è¡Œä¸ºå—é™ï¼Œä¸åªæ˜¯åœ¨æˆ‘ä»¬è¿™ä¸èƒ½å€Ÿæ¬¾ï¼Œåœ¨å“ªé‡Œéƒ½ä¸èƒ½å€Ÿæ¬¾ã€‚
        7. ä¸ç´§æ€¥è”ç³»äººæ²Ÿé€šï¼Œè®©ä»–ååŠ©è¿˜æ¬¾
        8ã€è”ç³»ä½ å·¥ä½œçš„å•ä½ï¼Œä¸ä½ çš„é¢†å¯¼è¿›è¡Œæ²Ÿé€šï¼Œäº†è§£ä½ çš„ç»æµçŠ¶å†µ
        9ã€åœ¨ç¤¾äº¤åª’ä½“ä¸Šä¸ä½ è¿›è¡Œæ²Ÿé€šï¼Œéœ€è¦è®©ä½ çŸ¥é“æˆ‘ä»¬å¯ä»¥åœ¨ç¤¾äº¤åª’ä½“ä¸Šæ‰¾æ‰“ä½ 
        10ã€å®‰æ’ç¬¬ä¸‰æ–¹ä¸Šé—¨è¿›è¡Œå‚¬æ”¶

        è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
        ã€åˆ†æã€‘ç®€è¦åˆ†æå®¢æˆ·çš„æŠ—æ‹’ç‚¹æˆ–å›°éš¾ï¼Œä»¥åŠå½“å‰ç­–ç•¥ä¸ºä½•æ— æ•ˆã€‚
        ã€å›æ¬¾å¯èƒ½æ€§ã€‘HIGH / MEDIUM / LOW
        ã€å»ºè®®æ–¹å‘ã€‘(å¦‚æœå¯èƒ½æ€§ä¸ºLOWï¼Œè¯·ä»ä¸Šè¿°6ç‚¹ä¸­é€‰æ‹©1-2ç‚¹å»ºè®®ï¼›å¦åˆ™ç•™ç©º)
        """
        user_prompt = f"""
ä»Šæ—¥å®Œæ•´å¯¹è¯å†å²ï¼š{json.dumps(chat_history, ensure_ascii=False, indent=2)}
"""
        return call_llm(user_prompt, system_prompt)

# --- Main App Logic ---

def main():
    # Sidebar: Configuration
    st.sidebar.title("âš™ï¸ Configuration")
    
    # Config File Selection
    config_files = [f for f in os.listdir("configs") if f.endswith(".yaml")]
    selected_config = st.sidebar.selectbox("Select Config", config_files, index=config_files.index("T0.yaml") if "T0.yaml" in config_files else 0)
    
    if selected_config:
        config = load_config(os.path.join("configs", selected_config))
    else:
        st.error("No config file found!")
        return

    # Customer Profile
    st.sidebar.subheader("Customer Profile")
    default_profile = {
        "name": "LESTARI",
        "amount": "Rp 1.250.000",
        "due_date": "2025-12-17",
        "current_time": "2025-12-17",
        "gender": "Male",
        "age": "30",
        "frenquency_borrow":"often",
        "payment_timelyness":"sometimes late",
        "meaber_level": "high"
    }
    profile_str = st.sidebar.text_area("Edit Profile (JSON)", json.dumps(default_profile, indent=2, ensure_ascii=False), height=250)
    try:
        customer_profile = json.loads(profile_str)
    except:
        st.sidebar.error("Invalid JSON in Profile")
        customer_profile = default_profile

    # History Logs
    st.sidebar.subheader("History Logs")
    default_history = '''
   ã€è¿‡å»èŠå¤©æ€»ç»“ã€‘
åœ¨ä¸Šä¸€è½®å‚¬æ”¶ä¸­å·²åšå‡ºæ˜ç¡®ã€å…·ä½“çš„è¿˜æ¬¾æ‰¿è¯ºï¼ˆå¦‚â€œä»Šå¤©ä¸‹åˆ3ç‚¹å‡†æ—¶è¿˜â€ï¼‰ï¼Œä½†åˆ°è¾¾æ‰¿è¯ºæ—¶é—´ç‚¹åï¼Œä¸ä»…æœªè¿˜æ¬¾ï¼Œä¸”å¯¹åç»­æ‰€æœ‰æé†’æ¶ˆæ¯å·²è¯»ä¸å›ï¼Œé™·å…¥å®Œå…¨é™é»˜ã€‚â€
    '''
    history_logs = st.sidebar.text_area("Edit History Logs", default_history, height=200)
    
    # Initialize Session State
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "strategy" not in st.session_state:
        st.session_state.strategy = None
    if "layer1_analysis" not in st.session_state:
        st.session_state.layer1_analysis = None

    # Reset Button
    if st.sidebar.button("Reset Session"):
        st.session_state.messages = []
        st.session_state.strategy = None
        st.session_state.layer1_analysis = None
        st.rerun()

        # --- Main Area ---
    st.title("ğŸ¤– Collection Agent (Easy Mode)")

    # Layout: 2 Columns
    # Col 1: Chat (60%)
    # Col 2: Strategy & Analysis (40%)
    col_chat, col_info = st.columns([2, 1.2])

    # --- Right Column: Strategy & Analysis ---
    with col_info:
        st.subheader("ğŸ§  Agent Brain (Strategy & Analysis)")
        
        # 1. Global Strategy (Layer 1)
        with st.expander("ğŸ“‹ Daily Strategy (Layer 1)", expanded=True):
            if not st.session_state.strategy:
                # Auto-initialize: Generate strategy and opening message immediately
                with st.spinner("Layer 1 Manager is analyzing history and generating strategy..."):
                    layer1 = Layer1StrategyManager(config, [history_logs])
                    full_strategy_output = layer1.generate_initial_strategy(customer_profile)
                    st.session_state.strategy = full_strategy_output
                    
                    # Generate opening message
                    layer2 = Layer2Executor(config)
                    opening_instruction = "(System Instruction: Start the conversation now. If this is a new contact, introduce yourself. If there is history, continue naturally based on the strategy.)"
                    # Pass history_logs for initial context
                    opening_response, thought = layer2.execute(full_strategy_output, [], opening_instruction, history_logs)
                    
                    st.session_state.messages.append({"role": "assistant", "content": opening_response, "thought": thought})
                    st.rerun()
            else:
                st.info(st.session_state.strategy)
                
                # Add a button to force regenerate strategy if needed
                if st.button("Regenerate Strategy"):
                    st.session_state.strategy = None
                    st.session_state.messages = [] # Also clear messages to restart conversation
                    st.rerun()
        
        st.divider()
        st.markdown("**Thinking Process Log**")

    # --- Left Column: Chat Interface ---
    with col_chat:
        st.subheader("ğŸ’¬ Chat Interface")

    # --- Render History ---
    for i, msg in enumerate(st.session_state.messages):
        # Chat Content (Col 1)
        with col_chat:
            with st.chat_message(msg["role"]):
                st.write(msg["content"])
        
        # Analysis Content (Col 2)
        if msg["role"] == "assistant":
            with col_info:
                st.markdown(f"**Turn {i+1} Analysis**")
                
                # Layer 3
                if "layer3_evaluation" in msg and msg["layer3_evaluation"]:
                    with st.expander("ğŸ›¡ï¸ Layer 3 Evaluation", expanded=False):
                        st.caption(msg["layer3_evaluation"])
                
                # Layer 1 Update Event
                if "layer1_update" in msg and msg["layer1_update"]:
                    st.warning(f"ğŸ”„ Strategy Updated at Turn {i+1}")
                    with st.expander("View New Strategy"):
                        st.caption(msg["layer1_update"])

                # Layer 2 Thought
                if "thought" in msg and msg["thought"]:
                    with st.expander("ğŸ’­ Layer 2 Thought", expanded=False):
                        st.caption(msg["thought"])
                
                st.divider()

    # --- User Input Handling ---
    if prompt := st.chat_input("Type your reply here..."):
        # 1. Render User Message immediately
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with col_chat:
            with st.chat_message("user"):
                st.write(prompt)

        # 2. Process Assistant Response
        # Initialize Layers
        layer1 = Layer1StrategyManager(config, [history_logs])
        layer2 = Layer2Executor(config)
        layer3 = Layer3Evaluator()

        # --- Layer 3: Evaluation ---
        with col_info:
            st.markdown(f"**Current Turn Analysis**")
            with st.spinner("ğŸ›¡ï¸ Layer 3 Evaluating..."):
                evaluation_output = layer3.evaluate(
                    st.session_state.messages,
                    [history_logs],
                    customer_profile,
                    st.session_state.strategy
                )
            
            with st.expander("ğŸ›¡ï¸ Layer 3 Evaluation", expanded=True):
                st.caption(evaluation_output)

        # Check for LOW probability trigger
        is_low_prob = "LOW" in evaluation_output or "å¯èƒ½æ€§ã€‘LOW" in evaluation_output
        
        layer1_update_text = None
        if is_low_prob:
            with col_info:
                with st.spinner("âš ï¸ Low probability! Updating Strategy..."):
                    new_strategy = layer1.update_strategy(
                        st.session_state.strategy, 
                        prompt, 
                        st.session_state.messages,
                        customer_profile,
                        evaluation_output
                    )
                    st.session_state.strategy = new_strategy
                    layer1_update_text = new_strategy
                    st.warning("ğŸ”„ Strategy Updated!")
                    with st.expander("View New Strategy"):
                        st.caption(new_strategy)

        # --- Layer 2: Execution ---
        with col_info:
            with st.spinner("ğŸ’­ Layer 2 Thinking..."):
                response, thought = layer2.execute(
                    st.session_state.strategy, 
                    st.session_state.messages[:-1], 
                    prompt,
                    history_logs  # Pass history logs here
                )
                with st.expander("ğŸ•µï¸ Layer 2 Execution Monitor (Thought)", expanded=True):
                    st.write(thought)
                st.divider()

        # --- Output Response ---
        with col_chat:
            with st.chat_message("assistant"):
                st.write(response)
        
        # Save to History
        st.session_state.messages.append({
            "role": "assistant", 
            "content": response, 
            "thought": thought,
            "layer3_evaluation": evaluation_output,
            "layer1_update": layer1_update_text
        })

    



if __name__ == "__main__":
    main()
